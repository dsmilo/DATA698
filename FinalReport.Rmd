---
title: "Executive Order 88 Energy Analytics & Data Cleansing"
author: "Dan Smilowitz"
output: 
  pdf_document: 
    fig_height: 5
    fig_width: 7
    highlight: pygments
fontsize: 12pt
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, comment = NA)
```

## Abstract
Some background, challenges, approach, findings -- WRITE LAST

## Problem Description

### Background
On December 28, 2012, New York Governor Andrew Cuomo issued [Executive Order 88](http://www.governor.ny.gov/news/no-88-directing-state-agencies-and-authorities-improve-energy-efficiency-state-buildings) requiring that

  > By April 1, 2020, all Affected State Entities shall collectively reduce the average EUI [Energy Use Intensity] in State-owned and managed buildings by at least 20% from a baseline of the average EUI ... for State fiscal year 2010/2011

The [New York Power Authority](https://www.nypa.gov) was charged with establishing a central management and implementation team to administer the executive order, directed and authorized to (among other responsibilities):

  - Take all appropriate measures to ensure that the order's target is met
  - Direct Affected State Entities to comply with the requirements of this order
  - Provide strategic, technical, and other assistance to each entity to support implementation
  - Develop annual milestones for achieving the target
  - Develop and implement reporting requirements to document each entity's progress toward the target
  - Develop a comprehensive operations and maintenance plan for the State's building portfolio to help achieve no cost and low cost efficiency improvements and ensure that efficiency savings are sustained

The Executive Order (EO88) led to the creation of NYPA's [BuildSmart NY](https://www.nypa.gov/innovation/programs/buildsmart-ny) program.  BuildSmart NY is a key part of Governor Cuomo's [Reforming the Energy vision](https://rev.ny.gov/) energy strategy and is the premier energy efficiency program referenced in the [2015 New York State Energy Plan](https://energyplan.ny.gov/Plans/2015.aspx).


### Challenges
Agencies are responsible for performing their own data validation --- the performance of this task has proved incomplete.  Many facilities have missing data for the baseline year, as well as showing large spikes or dips in reported usage believed to be due to data entry errors.  NYPA must ensure accurate data is used for the establishment of baselines and the tracking and reporting of performance.

EO88 reporting data has been hosted by a software vendor responsible for the the creation and maintenance of NYPA's [New York Energy Manager](https://www.nypa.gov/services/digital-energy-services/ny-energy-manager) (NYEM) platform.  The current structure of the data provides a great deal of redundancy and unused columns, harming the efficiency of computations based on this data.  Finally, the vendor's platform has been unable to properly handle the quality issues of reported data.

Finally, the NYEM platform and the [annual EO88 report](https://www.nypa.gov/-/media/nypa/documents/document-library/operations/eo88-annualreport-2016.pdf) produced by the BuildSmart NY team identify performance at agency and facility levels, but do not sufficiently highlight trends in the data, nor serve to identify performance by facility characteristics to allow for the development of new energy service offerings to help customer meet their required energy reductions.



## Data Preparation
An extract of the database was provided in two files -- one containing building data, and one containing reported consumption data.  The two extract files are imported and their structures investigated.
```{r load-extracts}
library(tidyverse)

bldg <- read_csv("data/2017-10-25_nyem-eo88_bldg-all-sfy.csv")
eo88 <- read_csv("data/2017-10-26_nyem-eo88_consumption-all-sfy.csv")
```


### Building Data
The building data set contains 126 columns, many of which correspond to reporting fields for each fiscal year.  There also a fair number of fields corresponding to building information independent of fiscal year.  To make more efficient use of storage, the data was converted using Hadley Wickham's [tidy data](http://vita.had.co.nz/papers/tidy-data.pdf) principles:

  - Data corresponding to each State Fiscal Year (SFY) was "gathered" to be represented as a field-value pair
  - SFY was extracted from each field name & stored as the SFY for each measure
  - Any duplicated entries were removed
  - SFY-dependent fields were "spread" so that each field is a column and has a value for each SFY
  - Spaces were removed from all field names to make references simpler

```{r tidy-bldg}
# tidy data that changes by SFY
bldg <- bldg %>%
  gather(Field, Value,
         `SFY2010-11 Gross Floor Area (ft2)`:
           `SFY2016-17 Property Type 5 Percent of Total Gross Floor Area`)

# separate FY from actual measure
bldg <- bldg %>%
  mutate(SFY = str_sub(Field, end = 10),
         Field = str_sub(Field, start = 12))

# remove duplicate entries per FY & ESP ID (unique identifier)
bldg <- bldg %>% distinct(`ESP Location ID`, SFY, Field, .keep_all = TRUE)

# spread FY-based fields
bldg <- bldg %>%
  spread(Field, Value)

# clean up bldg names
names(bldg) <- str_replace_all(names(bldg), " ", "")
```

Building metadata that remains constant and building data that may change by fiscal year were separated into two tables to join like operations and further optimize use of storage.  The primary key for each building is `ESPLocationID`; as such, this field is contained in both tables.
```{r split-bldg}
# create two dfs -- one with fixed data & hierarchy; other with SFY data
bldg_meta <- bldg %>% select(ESPLocationID, NYEMSystemID, AgencyName:NYSNOAAClimateRegion)
bldg_sfy  <- bldg %>% select(ESPLocationID, Status, SFY:`WeeklyOperatingHours(Hours/Week)`)
```

#### Fixed Building Metadata
The building metadata required only minor cleanup -- removing duplicate entries (arising from the repeating of these fields across fiscal years) and the renaming of fields for enhanced clarity in naming convention.
```{r clean-bldg-meta}
# remove duplicates from SFY duplication
bldg_meta <- distinct(bldg_meta)

# rename fields
bldg_meta <- bldg_meta %>%
  rename(Name = BuildingName,
         Agency = AgencyName,
         ClimateRegion = NYSNOAAClimateRegion,
         Address = BuildingAddress,
         City = BuildingCity,
         ZipCode = BuildingZipCode)
```

This fixed building metadata table is now far more compact, containing only 12 variables.


#### Variable Building Data
Building data varying across fiscal years required additional cleanup, as the names of fields are lengthy and not all variables are stored as the correct data type due to earlier transformations.  The following transformations were performed:

  - The redundant characters "SFY" were removed from the `SFY` field
  - Field names were adjusted:
    - Parentheses were removed from all field names
    - Long names were shortened to be more manageable
  - The unused `Type` field was removed
  - SFY-reported fields were converted from character to numeric

```{r clean-bldg-sfy}
# remove "SFY" from SFY field
bldg_sfy$SFY <- str_sub(bldg_sfy$SFY, 4)

# shorten long names, remove any parentheses
bldg_sfy <- bldg_sfy %>% 
  rename(FloorArea = `GrossFloorArea(ft2)`,
         PeakOccupants = PeakTotalOccupants,
         CooledPct = PercentofGrossFloorAreaCooled,
         HeatedPct = PercentofGrossFloorAreaHeated,
         Type_BEDES = `PropertyType(BEDES)`,
         Type_ES = `PropertyType(ES)`,
         WeeklyHours = `WeeklyOperatingHours(Hours/Week)`)

# shorten property & pct
names(bldg_sfy) <- str_replace_all(names(bldg_sfy), "Property", "")
names(bldg_sfy) <- str_replace_all(names(bldg_sfy), "PercentofTotalGrossFloorArea", "Pct")

# drop empty "Type" field
bldg_sfy <- bldg_sfy %>% select(-Type)

# convert fy-reported fields from character to numeric
bldg_sfy <- mutate_at(bldg_sfy,
  vars(FloorArea, PeakOccupants, CooledPct, HeatedPct, Type1Pct, Type2Pct,
       Type3Pct, Type4Pct, Type5Pct, WeeklyHours),
  parse_number)
```


This table is now far more reasonable for processing, and is properly tided and normalized, containing no fixed metadata fields.


### Consumption Data
The reported consumption dataset contains roughly 177,000 rows and 16 columns.  As with the two building datasets above, field names were modified to remove any spaces or parentheses and shortened to be more concise.  Fuel and units of measure of reported usage are reported as a single field; these were separated into separate fields to enable later analysis.
```{r eo88-names}
# clean up eo88 names
names(eo88) <- str_replace_all(names(eo88), " ", "")

# rename fields
eo88 <- eo88 %>%
  rename(Parent = ParentESPLocationID,
         FuelUnits = `FuelType(units)`,
         Start = BillingPeriodStart,
         End = BillingPeriodEnd,
         Utility = UtilityProvider,
         Demand = `Demand(kW)`)

# split fuel type & units
eo88 <- eo88 %>%
  mutate(Fuel = str_split(FuelUnits, " \\(", simplify = TRUE)[, 1],
         Units = str_split(FuelUnits, " \\(", simplify = TRUE)[, 2],
         Units = str_replace_all(Units, "\\)", ""))
```


#### Conversion to Source kBtu
Energy use intensity is calculated using a simple formula:
$$EUI = \frac{Energy\ Use}{Area}$$

Reported usage values span seven different units.  In order to create a unified view of EUI across all fuels, all reported usage must be converted to a single unit of measure.  The standard units for measuring EUI are thousands of British thermal units (kBtu) -- Energy Star Portfolio Manager provides extensive [Thermal Energy Converstions](https://portfoliomanager.energystar.gov/pdf/reference/Thermal%20Conversions.pdf) technical reference to handle these conversions.

Progress towards EO88 goals is measured using *source EUI*, which takes into account the total energy needed to make the energy used available (i.e. the amount of raw fuel needed to meet the consumption need).  Therefore, the kBtu must be converted from site energy use to source energy use.  Energy Star Portfolio Manager also provides a [Source Energy](https://portfoliomanager.energystar.gov/pdf/reference/Source%20Energy.pdf) technical reference, which shows that these conversion factors vary by fuel type.  These conversion factors vary over time based on changes in power generation.  To avoid changes in conversion of reported values between fiscal years, the BuildSmart NY team uses a fixed conversion table for all years; this table was used for conversion.
```{r souce-kbtu}
# read in converstion table to source kBtu (adapted from epa portfolio mgr)
eui_conv <- read_csv("data/2017-11-13_epa-portfolio-mgr_conversion-factors.csv")
## https://portfoliomanager.energystar.gov/pdf/reference/Thermal%20Conversions.pdf
## https://portfoliomanager.energystar.gov/pdf/reference/Source%20Energy.pdf

# convert to source kBtu
eo88 <- eo88 %>%
  # get multipliers
  left_join(eui_conv, by = "FuelUnits") %>%
  # convert to source energy
  mutate(Use = Use * kBtu_mult * source_mult) %>%
  # drop multipliers
  select(-kBtu_mult, -source_mult)
```


#### Removal of Redundant Data
The first seven of the 16 variables in the consumption data are also included in the building data.  Following conversion to source kBtu, these variables were removed (with the exception of `ESPLocationID`) to enforce normalization.  Additionally, the empty `Rate/ServiceClassification` was removed, as was the redundant variable containing the fuel & units (in favor of the separated `Fuel` and `Units` variables).
```{r eo88-select-vars}
# remove duplicated bldg data (& empty rate/sc) -- retrieve using esp id
eo88 <- eo88 %>% select(ESPLocationID, Parent, Utility, AccountNumber,
                        Start, End, Fuel, Units, Use, Demand, Cost)
```


#### Changes in Campus Reporting
One of the fields in the consumption data is `Parent` -- this indicates relationships between facilities where one facility may be a sub-facility of another (such as a college campus or office plaza).  Investigation of the consumption data revealed that not all `ESPLocationID` values supplied in the consumption data have associated values in the building data (fixed or variable).  Discussion with the BuildSmart NY team revealed that this occurs in two cases:

  - One facility with a number of sub-facilities was exempt from EO88 reporting & compliance
  - Many large college campuses moved from site-level reporting to campus-level reporting
  
Those sites that changed to campus-level reporting and are not included in the building metadata were changed to the `ESPLocationID` of the parent facility so that their information can be accurately included in calculation of performance in earlier fiscal years.  The `Parent` field was then removed, as it is no longer relevant.
```{r parent-facilities}
# remove data for irrelevant facilities with parent esp 5106
eo88 <- eo88 %>%
  filter(Parent != 5106)

# some sites went from building to campus reporting & are not in bldg_meta
# replace these (only sites not in bldg_meta) with parent ESP
eo88 <- eo88 %>%
  mutate(ESPLocationID = ifelse(ESPLocationID %in% bldg_meta$ESPLocationID,
                                ESPLocationID, Parent)) %>%
  select(-Parent)
```


### Mapping to Calendar Month
As outlined above, reporting for EO88 is based on New York State Fiscal Years, which span from April 1 to March 31 of the following year.  In order to accurately report on each State Fiscal Year's source EUI, reported usage must align with each State Fiscal Year, particularly the calendar months at the start and end of each SFY.  Investigation of billing period start & end dates shows that while an bills most commonly start at the beginning of the month and end at the end of the month, many bills start and/or end at other points in the month, with a strong trend towards roughly matching start and end days:
```{r day-plot}
# investigate billing month distribution
library(lubridate)
theme_set(theme_light())
eo88 %>% select(Start, End) %>%
  mutate_all(day) %>%
  ggplot(aes(x = Start, y = End)) +
  stat_bin_2d() +
  scale_fill_distiller(trans = "log10", breaks = c(1, 10, 100, 1000, 10000),
                      labels = c(1, 10, 100, "1k", "10k"),
                      direction = 1, na.value = "black") +
  labs(title = "Reported billing cycle start & end day of month",
       subtitle = "Count of occurences with given start & end day",
       x = "Bill start", y = "Bill end", fill = NULL) +
  theme_minimal() +
  theme(legend.direction = "horizontal", legend.position = c(0.9, 1.15),
        legend.justification = c(1, 1), legend.background = element_blank())
```

These values must be converted to contain the reported usage in a given month so that they can be mapped to State Fiscal years.  In order to accomplish this, a function is created that extracts, for each reported value:

  - Each calendar month the value encompasses
  - The number of days the billed value overlaps each month encompassed
  - The prorated share of usage per month, assuming flat usage through the period

This function was applied to each reported consumption value.  During application, the State Fiscal Year for each month is also added, and the bill start & end dates removed.  Finally, months falling outside the required reporting period (SFY 2010-11 through SFY 2016-17) were excluded.
```{r bill-to-cal, eval=FALSE}
# function to prorate billed dates to calendar dates & number of days in month
bill_to_cal <- function(start_dt, end_dt) {
  # create sequence of months
  tibble(Month = seq.Date(floor_date(start_dt, "m"), floor_date(end_dt, "m"), "m")) %>%
    # get # days in month
    ## same month: number of days in period (adding 1 to include first day)
    ## start month: days in start month - day of month (adding 1 to include first day)
    ## end month: day of end date
    ## between months: days in month (for periods that span > 2 months)
    mutate(
      Days = case_when(
        month(start_dt) == month(end_dt) ~ day(end_dt) - day(start_dt) + as.integer(1),
        Month == floor_date(start_dt, "m") ~ days_in_month(start_dt) - day(start_dt) + as.integer(1),
        Month == floor_date(end_dt, "m") ~ day(end_dt),
        TRUE ~ days_in_month(Month)),
      # get share of days in each month to scale reported values
      Share = Days / sum(Days))
}

# convert billed values to calendar month values -- not run in report due to long runtime
eo88 <- eo88 %>%
  mutate(cal_month = map2(Start, End, bill_to_cal)) %>%
  unnest() %>%
  select(-Start, -End, -Days) %>%
  # add SFY
  mutate(SFY = ifelse(month(Month) >= 4,
                      paste(year(Month), str_sub(year(Month) + 1, -2, -1), sep = "-"),
                      paste(year(Month) - 1, str_sub(year(Month), -2, -1), sep = "-")))

# remove months before SFY 10-11 & after FY 16-17 -- not run in report due to above conversion not being run
eo88 <- eo88 %>%
  filter(Month >= ymd("20100401"), Month <= ymd("20170331"))
```

```{r load-month-eo88}
# load eo88 data with calendar date conversion complete
load("data/data-prep.Rda")
```

Following this conversion to calendar dates, the building and consumption data are sufficiently prepared for analysis.

## Data Cleansing: Initial Approach
As identified in the *Problem Description* section above, a major issue encountered in analyzing and reporting EO88 performance is the presence of missing data, as well as possible abberant reported data.  In order to identify reported values in need of correction, a function is created to flag data points that met any of three criteria:

  - Missing usage data
  - Reported usage < 0
  - Reported usage that is an outlier for a given facility & fuel

```{r model-data-flag}
# create function to detect outliers
is.outlier <- function(out_var) {
  out_var < quantile(out_var, 0.25, na.rm = TRUE) - 1.5 * IQR(out_var, na.rm = TRUE) |
    out_var > quantile(out_var, 0.75, na.rm = TRUE) + 1.5 * IQR(out_var, na.rm = TRUE)
}

# flag values needing imputation (missing or outlier)
model_data <- eo88 %>%
  group_by(ESPLocationID, Fuel, Units) %>%
  mutate(Flagged = is.na(Use) | is.outlier(Use) | Use < 0) %>%
  ungroup()
```

The `caret` package was utilized to model more appropriate values for those values flagged.  Weather data from the National Climatic Data Center's [Divisional Data](https://www7.ncdc.noaa.gov/CDO/CDODivisionalSelect.jsp) was utilized to model this data using an array of methods:
```{r weather-import}
# get lookup values for climate regions
regions <- data_frame(
  Division = 1:10,
  ClimateRegion = c("Western Plateau", "Eastern Plateau", "Northern Plateau",
                    "Coastal", "Hudson Valley", "Mohawk Valley", "Champlain Valley",
                    "St. Lawrence Valley", "Great Lakes", "Central Lakes")
)

# read in NOAA weather data
weather <- read_csv("data/2017-11-14_NOAA_cdo-div-weather-indices.txt",
                    col_types = "iicnnnnnniinnnnnnnnn?")
## https://www7.ncdc.noaa.gov/CDO/CDODivisionalSelect.jsp

# convert weather YearMonth to date; drop extra columns
weather <- weather %>%
  mutate(YearMonth = ymd(paste0(YearMonth, "01"))) %>%
  rename(Month = YearMonth) %>%
  select(-StateCode, -X21)
```

  - Training a number of models on the entire as-is dataset
    - 4 linear models
    - 6 nonlinear models
    - 5 tree-based models
  - Training a k-nearest neighbors (KNN) model on the entire dataset
    - Using dummy variables for fuel & building type
    - Using transformed predictors
      - Centered & scaled
      - KNN-imputed
      - Highly-correlated & zero-variance predictors removed
  - Training a KNN model for each location
  - Training a KNN model for each fuel
  - Training a Cubist model for each location & fuel combination

Additionally, imputation was attempted using only data for a given facility & fuel in a given calendar month (with a window of $\pm$ 1 month added).
```{r model-data}
# join reporting data with bldg metadata, weather, bldg sfy data
model_data <- model_data %>%
  left_join(bldg_meta, by = "ESPLocationID") %>%
  left_join(regions, by = "ClimateRegion") %>%
  left_join(weather, by = c("Division", "Month")) %>%
  left_join(bldg_sfy %>% select(ESPLocationID, SFY, FloorArea, Type1),
            by = c("ESPLocationID", "SFY"))
```

Despite the varied approaches employed and hundreds of models fit to the data, the errors returned by resampling and evaluation against test sets were very high, often as high as the order of $1\times10^9$ kBtu.  To identify possible causes of this error, a facility with particularly high error across the models fit (`ESPLocationID` 92) was selected for investigation.  First, a boxplot of the non-missing usage values by fuel was created, separated by flagged & un-flagged values:
```{r 92-boxplot}
model_data %>%
  filter(ESPLocationID == 92, !is.na(Use)) %>%
  ggplot(aes(x = Flagged, y = Use, fill = Flagged)) +
  geom_boxplot(show.legend = FALSE) +
  scale_y_continuous(trans = "log10", breaks = 10^(2:7),
                     labels = c(100, "1k", "10k", "100k", "1M", "10M")) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank()) +
  facet_wrap(~ Fuel, scales = "free_y") +
  labs(title = "Distribution of reported usage values by fuel",
       subtitle = "Non-missing values for ESPLocationID 92")
```

This plot appears to show a relationship between fuel type, usage, and flagged status. For electricity, all but 3 values were over 100,000 kBtu, and none were flagged for correction.  For natural gas and steam, all values over roughly 100,000 kBtu were flagged for correction, and none below this threshold were flagged.  This was further investigated by creating a histogram of non-missing natural gas usage, colored by flag value;
```{r 92-histogram}
model_data %>%
  filter(ESPLocationID == 92, Fuel == "Natural Gas") %>%
  ggplot(aes(x = Use, y = ..count.. / sum(..count..), fill = Flagged)) +
  geom_histogram(bins = 25, col = "black") +
  scale_x_continuous(trans = "log10", breaks = 10^(2:8),
                     labels = c(100, "1k", "10k", "100k", "1M", "10M", "100M")) +
  scale_y_continuous("", labels = scales::percent) +
  theme(panel.grid.minor = element_blank(), legend.position = "top") +
  labs(title = "Distribution of monthly natural gas reported usage",
       subtitle = "Non-missing values for ESPLocationID 92")
```

This appears to confirm the bias towards flagging larger reported usage values.  This was interpreted as a side effect of the function used for flagging non-missing values -- since the scale of values varies so widely for some fuels, values two orders of magnitude higher than others will be flagged as outliers given the standard criteria of $x < Q1(X) - 1.5IQR(X)$ or $x > Q3(X) + 1.5IQR(X)$.  In order to address this, a log-transformation of reported usage values is considered prior to flagging data for correction.  Given that the two fuels identified above are thermal fuels with expected seasonal usage, the flagged status for natural gas usage is also investigated by month:
```{r 92-area}
model_data %>%
  filter(ESPLocationID == 92, !is.na(Use), Fuel == "Natural Gas",
         !SFY %in% c("2010-11", "2011-12", "2012-13")) %>%
  group_by(Month) %>%
  summarize(true = sum(Flagged == TRUE) / n(),
            false = 1 - true) %>%
  ungroup() %>%
  gather(Flagged, Share, -(Month)) %>%
  mutate(Flagged = if_else(Flagged == "true", TRUE, FALSE)) %>%
  ggplot(aes(Month, Share, fill = Flagged, col = Flagged)) +
  geom_area() +
  theme(legend.position = "top") +
  scale_y_continuous(labels = scales::percent) +
  scale_x_date(NULL, date_breaks = "3 months", date_labels = "%Y\n%m") +
  labs(title = "Monthly share of natural gas usage values flagged for correction",
       subtitle = "Non-missing values for ESPLocationID 92")
```

This plot shows clear seasonality, with far more values flagged for correction in winter months.  This makes sense given the earlier observation of higher values being flagged, as natural gas is intuitively expected to have higher usage in winter months given its use for heating.

These patterns, as well as the poor accuracy of attempted data correction, were brought to the BuildSmart NY and NYEM teams to help identify a solution to improve accuracy and reduce any bias.  The NYEM team, after conversation with the vendor that provided the data extract, revealed that **all provided values has already been verified by the reporting agencies.**  This information changed the direction of the approach: data no longer needed to be flagged for imputation; only missing values needed to be filled.


## Data Cleansing: Revised Approach
The redefined scope of this project called for a focus on only missing values.  Prior to investigating these missing values, the overall distribution of reported usage values was investigated:
```{r overall-boxplot}
# set up df to flag imputed & method
eo88_imp <- eo88 %>% mutate(Imputed = character(nrow(eo88)))

# investigate distribution of Use values by SFY
ggplot(eo88_imp, aes(x = SFY, y = Use)) + geom_boxplot() +
  ggtitle("Distribution of reported usage values by SFY")
```

There are two values in SFY 2010-11, one positive and one negative, that are well beyond the scale of all other reported values.  These two extreme values (the overall maximum and minimum) are investigated; usage for the facilities and fuels corresponding to the extreme values are plotted by account number:
```{r extremes-plot}
# investigate two extreme values (1.6e+9 & 1.6e-9)
extremes <- eo88_imp %>%
  filter(Use == max(Use, na.rm = TRUE) | Use == min(Use, na.rm = TRUE)) %>%
  select(ESPLocationID, Fuel, AccountNumber, Month, Use, Demand, Cost)

eo88_imp %>%
  filter(ESPLocationID %in% extremes$ESPLocationID, Fuel %in% extremes$Fuel) %>%
  ggplot(aes(x = Month, y = Use)) +
  geom_line() +
  facet_wrap(ESPLocationID ~ AccountNumber, scales = "free_y") +
  labs(title = "Usage for facilities with maximum & minimum reported monthly usage",
       subtitle = "Usage shown by ESPLocationID & account number",
       caption = "All accounts for fuel containing max & min values shown")
```

The maximum ($\sim 1.6 \times 10^9$) and minimum ($\sim -1.6 \times 10^9$) reported monthly kBtu occur for the same facility (`ESPLocationID` 324), fuel (Electricity, grid purchase), and account number (*Electric-291010012800006*) in consecutive months (January-February 2011).  While these numbers have been verified by the reporting agency (per the NYEM team), it is likely that these two errors represent a billing or metering error followed by a corresponding correction.  To avoid any errors in reporting that may be caused by these extreme values, both were replaced by the mean use of the two months; the same is performed for cost and demand.  A modified version of the consumption data set was created with an additional variable `Imputed` added to track all imputations performed; this change is recorded as *manual*.
```{r extremes-impute}
eo88_imp <- eo88_imp %>%
  mutate(Imputed = replace(Imputed, which(Use %in% extremes$Use), "manual"),
         Use = replace(Use, which(Use %in% extremes$Use), mean(extremes$Use)),
         Demand = replace(Demand, which(Demand %in% extremes$Demand), mean(extremes$Demand)),
         Cost = replace(Cost, which(Cost %in% extremes$Cost), mean(extremes$Cost)))
```

To understand missing values and how they may be imputed, the frequency and patterns of missingness were investigated using the `mice` package (note that the `Imputed` variable was created as an empty character string to avoid obfuscating missingness patterns):
```{r aggr-allvars}
library(mice)
library(pander)
md.pattern(eo88_imp) %>% t() %>% pander()
```

It is clear that only three reported variables contain missing values -- `Use`, `Demand`, and `Cost`.  The patterns in missing data between these variables were visualized using the `VIM` package:
```{r aggr}
eo88_imp %>%
  select(Use, Demand, Cost) %>% 
  VIM::aggr(numbers = TRUE, prop = FALSE, bars = FALSE, cex.numbers = 0.9)
```

The left segment of this plot shows that there are roughly 10,000 cases missing `Use`, roughly 8,000 missing `Cost`, and over 200,000 missing `Demand` -- this last number is sensible since the original name of the field specifically referenced kW and therefore would only apply to electricity.  The right segment shows that there are six patterns in which data is missing some or all of these variables, with the most common being missing only demand.

For the purposes of Executive Order 88 analysis and reporting, demand and cost are of no immediate import; only use is of concern, as it is used to calculate source EUI.  There are only three patterns of missingness which involve missing use:

  - Missing use; reported demand; reported cost (7 instances)
  - Missing use; missing demand; missing cost (618 instances)
  - Missing use; missing demand; reported cost (9302 instances)

Each of these patterns is investigated individually, as the approach to imputing the missing values will likely vary.

### Reported Demand & Cost
The instances of missing reported use with reported demand and cost all occur for the same account (*Electric-495520212030000*) in consecutive months (April-October 2012); the demand and cost values for each of these months is zero.  Investigation with NYPA staff reveals that this account did not exist prior to November 2012 -- it is likely that the reported zero demand and cost were back-filled to populate the State Fiscal Year with data.  These use values are imputed with zero and flagged with an `Imputed` tag of *zero*.
```{r reported-demand-cost}
eo88_imp <- eo88_imp %>%
  mutate(Imputed = if_else(is.na(Use) & !is.na(Demand) & !is.na(Cost), "zero", Imputed),
         Use = if_else(is.na(Use) & !is.na(Demand) & !is.na(Cost), 0, Use))
```


### No Demand or Cost
For accounts containing entries missing each of cost, demand, and cost, the share of months containing all missing values was calculated, and the distribution of accounts by share investigated:
```{r trip-na-share}
trip_na <- eo88_imp %>%
  filter(is.na(Use), is.na(Demand), is.na(Cost)) %>%
  select(AccountNumber, Month) %>%
  distinct()

eo88_imp %>%
  filter(AccountNumber %in% trip_na$AccountNumber) %>%
  group_by(AccountNumber) %>%
  summarize(allna = sum(is.na(Use) & is.na(Demand) & is.na(Cost)),
            notall = n() - allna, sharena = allna / n()) %>%
  ggplot(aes(x = sharena)) +
  geom_histogram(binwidth = 0.1, alpha = 0.5, col = "black") +
  scale_x_continuous(breaks = seq(0, 1, 0.2), labels = scales::percent) +
  labs(title = "Distribution of share of months with use, demand, and cost missing",
       subtitle = "For all accounts with at least one month missing all three values",
       x = "Share of months", y = "Count")
```

The two account numbers with 100% all-missing values both belong to the same facility and span only April 2011 through April 2012.  Investigation of the variable building data revealed that the `Status` of this facility in SFY 2011-12 and SFY 2012-13 was *excluded*, meaning that its usage is not reported as part of EO88 compliance.  To investigate if this explained all missing values, the consumption and building data sets were joined and data missingness reexamined.  Over 98% of missing values still remained, so further investigation was continued, and excluded values were considered throughout.

Electricity grid purchases were investigated first by visualizing the accounts containing at least one month missing all three values:
```{r tripna-elec}
eo88_imp %>%
  filter(AccountNumber %in% trip_na$AccountNumber, Fuel == "Electricity, grid purchase") %>%
  select(AccountNumber, Month, Use, Demand, Cost) %>%
  group_by(AccountNumber) %>%
  mutate(Missing = is.na(Use) & is.na(Demand) & is.na(Use),
         Use = ifelse(Missing, 0, Use)) %>%
  ggplot(aes(Month, Use, col = Missing)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ AccountNumber, scales = "free") +
  scale_y_continuous(NULL, NULL, NULL) +
  theme(panel.grid = element_blank(), legend.position = c(0.65, 0.05), legend.direction = "horizontal") +
  labs(title = "Reported eletricity grid purchase usage",
       subtitle = "For accounts with months missing use, demand, and cost",
       x = NULL)
```

Many of these accounts appear to have missing values before and/or after data was reported with non-missing values.  Given the back-filling seen in the above section to make reported values line up with State Fiscal Years, it was assumed that these accounts followed the same pattern.  Missing use values for these accounts in months also missing demand and cost were filled with zero and tagged as *zero* imputation.

Six of the accounts do not appear to follow this pattern -- their all-missing values do not fall before or after periods with non-missing values.  These values were flagged for further imputation -- given the lack of other reported values (demand and cost), an approach that incorporated other data was selected.  The weather data that was acquired for the initial approach was identified as data for use in imputation, and random forest imputation was selected as the preferred method due to its low variance and bias.  These values were tagged with *rf* imputation but left as missing until all investigation is complete.

```{r flag-elec-tripna}
### many before or after reporting --- likely cancelled accts -- get six not
elec_trip <- c("Electric-1001-226-0906", "Electric-1001-6581-323", "Electric-41861-58005",
               "Electric-495301090000005", "Electric-695320202500015", "Electric-9564-007-100")

elec_cancelled <- eo88_imp %>%
  filter(Fuel == "Electricity, grid purchase",
         AccountNumber %in% trip_na$AccountNumber,
         !AccountNumber %in% elec_trip) %>%
  pull(AccountNumber) %>%
  unique()


### fill cancelled with zeroes
eo88_imp <- eo88_imp %>%
  mutate(Imputed = if_else(AccountNumber %in% elec_cancelled &
                             is.na(Use) & is.na(Demand) & is.na(Cost),
                           "zero", Imputed),
         Use = if_else(AccountNumber %in% elec_cancelled &
                         is.na(Use) & is.na(Demand) & is.na(Cost),
                       0, Use))

### flag others for imputation -- assume random forest due to unkown relationship with weather
eo88_imp <- eo88_imp %>%
  mutate(Imputed = if_else(AccountNumber %in% elec_trip &
                             is.na(Use) & is.na(Demand) & is.na(Cost),
                           "rf", Imputed))
```

A large number of account number for thermal fuels (fuel oil #2, natural gas, kerosene, propane, and steam) contained missing use, cost, and demand.  Inspection of the patterns of these missing values reflected periods of usage followed by no use as well as periodic purchases.  Both of these patterns make intutitive sense for thermal fuels, as they are highly seasonal; further, some fuels are reserve-based -- a consumer purchases a reserve of fuel and uses it in a non-metered fashion.  Based on this, the "triple-missing" values for thermal fuels were imputed with zero.
```{r tripna-thermal}
eo88_imp <- eo88_imp %>%
  mutate(Imputed = if_else(is.na(Use) & is.na(Demand) & is.na(Cost) &
                         Fuel != "Electricity, grid purchase",
                       "zero", Imputed),
         Use = if_else(is.na(Use) & is.na(Demand) & is.na(Cost) &
                         Fuel != "Electricity, grid purchase",
                       0, Use))
```

The only rows in the consumption database missing each of use, demand, and cost are now those flagged for imputation using a random forest model:
```{r aggr-after-tripna}
eo88_imp %>%
  select(Use, Demand, Cost) %>% 
  VIM::aggr(numbers = TRUE, prop = FALSE, bars = FALSE, cex.numbers = 0.9)
```


### Reported Cost; No Demand

### Data Imputation

#### Random Forest

#### Regression

#### Results


## Export to Database


## Performance Analysis

### In-Database Calculation

### In-Memory Calculation

#### Visualization

### Analysis by Segments


## Future Improvements

## Acknowledgements
Thank you to Honey Berk for her guidance in overcoming the myriad challenges encountered throughout the course of this project.  Thank you also to Gabe Cowles, Ryan Droege, Srini Pusuluri, Joe O'Connor, Julie Reardon, Prasad Surapaneni, and Godly Varghese for their assistance in the acquisition and understanding of the data used for this project.  


## References
Hadley Wickham (2017). tidyverse: Easily Install and Load the 'Tidyverse'. R package version 1.2.1. https://CRAN.R-project.org/package=tidyverse

Hadley Wickham and Edgar Ruiz (2017). dbplyr: A 'dplyr' Back End for Databases. R package version 1.1.0.9000. https://github.com/tidyverse/dbplyr

Jim Hester and Hadley Wickham (2017). odbc: Connect to ODBC Compatible Databases (using the DBI Interface). R package version 1.1.1.9000. https://github.com/rstats-db/odbc

R Special Interest Group on Databases (R-SIG-DB), Hadley Wickham and Kirill Müller (2017). DBI: R Database Interface. R package version 0.7. https://CRAN.R-project.org/package=DBI

Stef van Buuren, Karin Groothuis-Oudshoorn (2011). mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1-67. http://www.jstatsoft.org/v45/i03/.

Alexander Kowarik, Matthias Templ (2016). Imputation with the R Package VIM. Journal of Statistical Software, 74(7), 1-16. doi:10.18637/jss.v074.i07

Gergely Daróczi and Roman Tsegelskyi (2017). pander: An R 'Pandoc' Writer. R package version 0.6.1. https://CRAN.R-project.org/package=pander

Garrett Grolemund, Hadley Wickham (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25. URL http://www.jstatsoft.org/v40/i03/.

Governor Andrew M. Cuomo (2012). Executive Order No. 88: Directing State Agencies and Authorities to Improve the Energy Efficiency of State Buildings. http://www.governor.ny.gov/news/no-88-directing-state-agencies-and-authorities-improve-energy-efficiency-state-buildings.

Energy Star Portfolio Manager (2015). Technical Reference: Thermal Energy Conversions. https://portfoliomanager.energystar.gov/pdf/reference/Thermal%20Conversions.pdf

Energy Star Portfolio Manager (2013). Technical Reference: Source Energy. https://portfoliomanager.energystar.gov/pdf/reference/Source%20Energy.pdf

National Oceanic and Atmospheric Administration (2017). Divisional Data Select. https://www7.ncdc.noaa.gov/CDO/CDODivisionalSelect.jsp

New York Power Authority (2017). BuildSmart NY. https://www.nypa.gov/innovation/programs/buildsmart-ny

New York Power Authority (2017). NY Energy Manager. https://www.nypa.gov/services/digital-energy-services/ny-energy-manager

BuildSmart NY (2016).  EO88 2016 Annual Report. https://www.nypa.gov/-/media/nypa/documents/document-library/operations/eo88-annualreport-2016.pdf

Edgar Ruiz (2017). dbplot: Simplifies Plotting Data Inside Databases. R package version 0.1.1. https://CRAN.R-project.org/package=dbplot

Max Kuhn (2017). caret: Classification and Regression Training. R package version 6.0-78. https://CRAN.R-project.org/package=caret
