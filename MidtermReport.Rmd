---
title: "DATA 698 Midterm Report: Executive Order 88 Energy Analytics & Data Cleansing"
author: "Dan Smilowitz"
date: "November 3, 2017"
output: 
  pdf_document: 
    fig_caption: yes
    fig_height: 5
    fig_width: 7
    highlight: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = NA, fig.align = "center")
```

# Background
On December 28, 2012, New York Governor Andrew Cuomo issued [Executive Order 88](http://www.governor.ny.gov/news/no-88-directing-state-agencies-and-authorities-improve-energy-efficiency-state-buildings) requiring that

  > By April 1, 2020 ... State Entities shall collectively reduce the average EUI [Energy Use Intensity] ... by at least 20% from a baseline of the average EUI ... for State fiscal year 2010/2011

The [New York Power Authority](https://www.nypa.gov) (NYPA) was charged with establishing a management and implementation team to administer the executive order, directed to ensure agencies' compliance by implementing reporting requirements to document progress toward the target.  In order to track performance against baselines, NYPA's [BuildSmart NY](https://www.nypa.gov/innovation/programs/buildsmart-ny) team collects utility bill information for all fuels (e.g. electricity, natural gas, and water) for all covered facilities as compared to the square footage of each facility.  This information is reported by each agency and submitted to NYPA in the form of an Excel spreadsheet template.  


## Challenges
Agencies are responsible for performing their own data validation --- the performance of this task has proved incomplete.  Many facilities have missing data for the baseline year, as well as showing large spikes or dips in reported usage believed to be due to data entry errors.  NYPA must ensure accurate data is used for the establishment of baselines and the tracking and reporting of performance.

EO88 reporting data has been hosted by a software vendor responsible for the the creation and maintenance of NYPA's [New York Energy Manager](https://www.nypa.gov/services/digital-energy-services/ny-energy-manager) (NYEM) platform.  The current structure of the data provides a great deal of redundancy and unused columns, harming the efficiency of computations based on this data.  Finally, the vendor's platform has been unable to properly handle the quality issues of reported data.

Finally, the NYEM platform and the [annual EO88 report](https://www.nypa.gov/-/media/nypa/documents/document-library/operations/eo88-annualreport-2016.pdf) produced by the BuildSmart NY team identify performance at agency and facility levels, but do not sufficiently highlight trends in the data, nor serve to identify performance by facility characteristics to allow for the development of new energy service offerings to help customer meet their required energy reductions.


## Expected Approaches \& Required Delivery
In order to emable expanded analysis, the data will be converted to a "tidy" format and stored in a properly normalized SQL database, as the volume of data may make in-memory storage impractical.  The database may be operationalized by NYPA; Microsoft SQL Server will be utilized to match NYPA's enterprise architecture.  The analyses for this project (conducted in R), may be leveraged into enterprise data integration and visalization softwares to allow automated ingestion into a cloud platform.

The method for handling of missing data has not yet been determined, but it is expected that values will be imputed for based on other reported values for each facility, in combination with data for similar facilities and weather data (possibly that provided through NYEM).  A method for flagging possibly-abberant data will also be established, likely based on change from previous months.

------------------------------------
\newpage


# Data Processing
The data provided from the above-mentioned software vendor was provided in two files, one containing building data and the other containing reported consumption data.  These files are read into R:

```{r load-data}
library(tidyverse)

bldg <- read_csv("data/2017-10-25_nyem-eo88_bldg-all-sfy.csv")
eo88 <- read_csv("data/2017-10-26_nyem-eo88_consumption-all-sfy.csv")
```

## Building Data
The structure of the building information dataset is investigated:
```{r summ-bldg}
#devtools::install_github("ropenscilabs/skimr")
skimr::skim_with(
  character = list(min = NULL, max = NULL, empty = NULL, n = NULL, complete = NULL),
  integer = list(complete = NULL, n = NULL, mean = NULL, sd = NULL, min = NULL,
                 p25 = NULL, p75 = NULL, max = NULL, hist = NULL),
  numeric = list(complete = NULL, n = NULL, mean = NULL, sd = NULL, min = NULL,
                 p25 = NULL, p75 = NULL, max = NULL, hist = NULL, median = NULL))
skimr::skim(bldg)
```


The `bldg` data frame contains 126 columns, many of which correspond to reporting fields for each fiscal year.  There also a fair number of fields corresponding to building information independent of fiscal year.  To make more efficient use of storage, the data is converted using Hadley Wickham's [tidy data](http://vita.had.co.nz/papers/tidy-data.pdf) principles:
```{r tidy-bldg}
# tidy data that changes by SFY
bldg <- bldg %>%
  gather(Field, Value,
         `SFY2010-11 Gross Floor Area (ft2)`:
           `SFY2016-17 Property Type 5 Percent of Total Gross Floor Area`)

# separate FY from actual measure
library(stringr)
bldg <- bldg %>% 
  mutate(SFY = str_sub(Field, end = 10),
         Field = str_sub(Field, start = 12))

# remove duplicate entries per FY & ESP ID (unique identifier)
bldg <- bldg %>% distinct(`ESP Location ID`, SFY, Field, .keep_all = TRUE)

# spread FY-based fields
bldg <- bldg %>% 
  spread(Field, Value)

# clean up names for easier manipulation
names(bldg) <- str_replace_all(names(bldg), " ", "")
```

Building metadata that remains constant and building data that may change by fiscal year are separated into two tables to join like operations and further optimize use of storage.  The primary key for each building is `ESPLocationID`; as such, this field is contained in both tables:
```{r split-bldg}
# create two dfs -- one with fixed data & hierarchy; other with SFY data
bldg_meta <- bldg %>% select(ESPLocationID:NYSNOAAClimateRegion)
bldg_sfy  <- bldg %>% select(ESPLocationID, SFY:`WeeklyOperatingHours(Hours/Week)`)
```


### Fixed Building Metadata
The building metadata requires only minor cleanup -- removing duplicate entries (arising from the repeating of these fields across fiscal years) and the renaming of fields
```{r clean-bldg-meta}
# remove duplicates
bldg_meta <- distinct(bldg_meta)

# rename & reorder fields
bldg_meta <- bldg_meta %>% 
  rename(Name = BuildingName,
         Agency = AgencyName,
         ClimateRegion = NYSNOAAClimateRegion,
         Address = BuildingAddress,
         City = BuildingCity,
         ZipCode = BuildingZipCode,
         Included = Status)

# convert included field to boolean
bldg_meta$Included <- bldg_meta$Included == "included"
```


### Variable Building Data
Building data varying across fiscal years requires additional cleanup, as the names of fields are lengthy and not all variables are stored as the correct data type due to earlier transformations.

```{r clean-bldg-sfy}
# remove redundant "SFY" from SFY field
bldg_sfy$SFY <- str_sub(bldg_sfy$SFY, 4)

# shorten long names & remove any parentheses
bldg_sfy <- bldg_sfy %>%
  rename(FloorArea = `GrossFloorArea(ft2)`,
         PeakOccupants = PeakTotalOccupants,
         CooledPct = PercentofGrossFloorAreaCooled,
         HeatedPct = PercentofGrossFloorAreaHeated,
         Type_BEDES = `PropertyType(BEDES)`,
         Type_ES = `PropertyType(ES)`,
         WeeklyHours = `WeeklyOperatingHours(Hours/Week)`)

# shorten property & percentage
names(bldg_sfy) <- str_replace_all(names(bldg_sfy), "Property", "")
names(bldg_sfy) <- str_replace_all(names(bldg_sfy), "PercentofTotalGrossFloorArea", "Pct")

# drop empty "Type" field
bldg_sfy <- bldg_sfy %>% select(-Type)

# convert fy-reported fields from character to numeric
bldg_sfy <- mutate_at(bldg_sfy,
  vars(FloorArea, PeakOccupants, CooledPct, HeatedPct, Type1Pct, Type2Pct,
       Type3Pct, Type4Pct, Type5Pct, WeeklyHours),
  parse_number)
```

The two tables are now far more reasonable and are properly normalized:
```{r summ-newbldg}
skimr::skim(bldg_meta)
skimr::skim(bldg_sfy)
```

## Creation of Database
With the building data properly handled, the SQL Server database is created and populated with the two tables:
```{r create-db}
library(DBI)
library(odbc)

# connect to local SQL Server instance
con <- dbConnect(odbc(), Driver = "{SQL Server}", Server = Sys.getenv("USERDOMAIN"))

# create EO88 db
dbSendQuery(con, "DROP DATABASE IF EXISTS EO88;")
dbSendQuery(con, "CREATE DATABASE EO88;")
dbSendQuery(con, "USE EO88;")

# write two building tables
dbWriteTable(con, "building_fixed", bldg_meta, row.names = FALSE)
dbWriteTable(con, "building_variable", bldg_sfy, row.names = FALSE)

# disconnect from server for sanitation while working on eo88 data
dbDisconnect(con)
```


## Consumption Data
The structure of the EO88 reported consumption data is investigated:
```{r str-eo88}
str(eo88, give.attr = FALSE)
```

The `bldg` data frame contains roughly 177,000 rows and 16 columns -- the first seven of these contain data also included in the `bldg_meta` dataframe -- these are removed to enforce normalization, with the exception of ESP Location ID, which is the unique identifier used to join the two tables.  The fuel and units measures are also split into separate columns:
```{r clean-eo88}
# clean up eo88 names
names(eo88) <- str_replace_all(names(eo88), " ", "")

# rename fields
eo88 <- eo88 %>% 
  rename(Parent = ParentESPLocationID,
         FuelUnits = `FuelType(units)`,
         Start = BillingPeriodStart,
         End = BillingPeriodEnd,
         Utility = UtilityProvider,
         Demand = `Demand(kW)`)

# split fuel type & units
eo88 <- eo88 %>%
  mutate(Fuel = str_split(FuelUnits, " \\(", simplify = TRUE)[, 1],
         Units = str_split(FuelUnits, " \\(", simplify = TRUE)[, 2],
         Units = str_replace_all(Units, "\\)", "")) %>% 
  select(-FuelUnits)

# remove missing usage rows
eo88 <- drop_na(eo88, Use)
```

### Date Normalization
Before the EO88 reporting data can be added to the database and used for analysis, the billing dates will need to be converted to match calendar months.
